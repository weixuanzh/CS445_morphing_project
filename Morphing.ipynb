{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7204bd4-5f75-4fe5-a568-704a45d09d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "def select_points(img, title=\"Select points\"):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    points = plt.ginput(n=-1, timeout=0)\n",
    "    plt.close()\n",
    "    return np.array(points)\n",
    "\n",
    "def add_boundary_points(img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    return np.array([\n",
    "        [0, 0], [w-1, 0], [w-1, h-1], [0, h-1],\n",
    "        [w//2, 0], [w-1, h//2], [w//2, h-1], [0, h//2]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e7a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize images\n",
    "img1 = cv2.imread('face_img.jpg', cv2.IMREAD_COLOR)\n",
    "img2 = cv2.imread('lion_img.jpg', cv2.IMREAD_COLOR)\n",
    "h, w = img1.shape[:2]\n",
    "img2 = cv2.resize(img2, (w, h))  # Make sure they are same size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select points\n",
    "points1 = select_points(img1, \"Select keypoints for Woman\")\n",
    "points2 = select_points(img2, \"Select corresponding keypoints for Lion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add boundary points\n",
    "boundary = add_boundary_points(img1.shape)\n",
    "points1 = np.vstack([points1, boundary])\n",
    "points2 = np.vstack([points2, boundary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a178fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangulate based on average shape\n",
    "average_points = (points1 + points2) / 2\n",
    "tri = Delaunay(average_points)\n",
    "\n",
    "# Plot the triangulation\n",
    "plt.triplot(average_points[:,0], average_points[:,1], tri.simplices)\n",
    "plt.plot(average_points[:,0], average_points[:,1], 'o')\n",
    "plt.title(\"Triangulation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35f93f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5  # Half woman, half lion\n",
    "morphed_img = np.zeros_like(img1, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a717822",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tri_indices in tri.simplices:\n",
    "    # Get vertices of current triangle\n",
    "    x1 = points1[tri_indices]\n",
    "    x2 = points2[tri_indices]\n",
    "    x = average_points[tri_indices]  # Intermediate points\n",
    "\n",
    "    # Compute affine transforms\n",
    "    warp_mat1 = cv2.getAffineTransform(np.float32(x1), np.float32(x))\n",
    "    warp_mat2 = cv2.getAffineTransform(np.float32(x2), np.float32(x))\n",
    "\n",
    "    # Warp each triangle separately\n",
    "    img1_warped = cv2.warpAffine(img1, warp_mat1, (w, h))\n",
    "    img2_warped = cv2.warpAffine(img2, warp_mat2, (w, h))\n",
    "\n",
    "    # Create mask for the triangle\n",
    "    mask = np.zeros((h, w), dtype=np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(x), 1.0, 16, 0)\n",
    "\n",
    "    # Add to morphed image\n",
    "    morphed_img += mask * ((1 - alpha) * img1_warped + alpha * img2_warped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33d29062",
   "metadata": {},
   "outputs": [],
   "source": [
    "morphed_img = np.clip(morphed_img, 0, 255).astype(np.uint8)\n",
    "plt.imshow(morphed_img, cmap='gray')\n",
    "plt.title('Morphed Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bff11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "def morph_triangle(img1, img2, img, t1, t2, t, alpha):\n",
    "    # Compute affine transform matrices\n",
    "    warp_mat1 = cv2.getAffineTransform(np.float32(t1), np.float32(t))\n",
    "    warp_mat2 = cv2.getAffineTransform(np.float32(t2), np.float32(t))\n",
    "\n",
    "    # Warp triangles\n",
    "    warped_img1 = cv2.warpAffine(img1, warp_mat1, (img.shape[1], img.shape[0]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "    warped_img2 = cv2.warpAffine(img2, warp_mat2, (img.shape[1], img.shape[0]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    # Mask for the triangle\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t), 1.0, 16, 0)\n",
    "\n",
    "    # Blend the triangles\n",
    "    img += mask * ((1.0 - alpha) * warped_img1 + alpha * warped_img2)\n",
    "\n",
    "def morph_images(img1, img2, points1, points2, tri, alpha):\n",
    "    h, w, c = img1.shape  \n",
    "    morphed_img = np.zeros((h, w, c), dtype=np.float32)\n",
    "\n",
    "    points = (1 - alpha) * points1 + alpha * points2\n",
    "\n",
    "    for tri_indices in tri.simplices:\n",
    "        x1 = points1[tri_indices]\n",
    "        x2 = points2[tri_indices]\n",
    "        x = points[tri_indices]\n",
    "\n",
    "        # For each channel separately\n",
    "        for ch in range(c):\n",
    "            morph_triangle(img1[:,:,ch], img2[:,:,ch], morphed_img[:,:,ch], x1, x2, x, alpha)\n",
    "\n",
    "    return np.clip(morphed_img, 0, 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up Video Writer\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4\n",
    "# video_out = cv2.VideoWriter('morph_video.mp4', fourcc, 15.0, (w, h), isColor=True)  # 15 fps, grayscale video\n",
    "\n",
    "# # Create morph frames\n",
    "# num_frames = 100  # Number of frames in the video\n",
    "# for i, alpha in enumerate(np.linspace(0, 1, num_frames)):\n",
    "#     print(f\"Generating frame {i+1}/{num_frames}...\")\n",
    "#     frame = morph_images(img1, img2, points1, points2, tri, alpha)\n",
    "#     video_out.write(frame)\n",
    "\n",
    "# video_out.release()\n",
    "# print(\"Morphing video saved as 'morph_video.mp4'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating forward frame 1/100...\n",
      "Generating forward frame 2/100...\n",
      "Generating forward frame 3/100...\n",
      "Generating forward frame 4/100...\n",
      "Generating forward frame 5/100...\n",
      "Generating forward frame 6/100...\n",
      "Generating forward frame 7/100...\n",
      "Generating forward frame 8/100...\n",
      "Generating forward frame 9/100...\n",
      "Generating forward frame 10/100...\n",
      "Generating forward frame 11/100...\n",
      "Generating forward frame 12/100...\n",
      "Generating forward frame 13/100...\n",
      "Generating forward frame 14/100...\n",
      "Generating forward frame 15/100...\n",
      "Generating forward frame 16/100...\n",
      "Generating forward frame 17/100...\n",
      "Generating forward frame 18/100...\n",
      "Generating forward frame 19/100...\n",
      "Generating forward frame 20/100...\n",
      "Generating forward frame 21/100...\n",
      "Generating forward frame 22/100...\n",
      "Generating forward frame 23/100...\n",
      "Generating forward frame 24/100...\n",
      "Generating forward frame 25/100...\n",
      "Generating forward frame 26/100...\n",
      "Generating forward frame 27/100...\n",
      "Generating forward frame 28/100...\n",
      "Generating forward frame 29/100...\n",
      "Generating forward frame 30/100...\n",
      "Generating forward frame 31/100...\n",
      "Generating forward frame 32/100...\n",
      "Generating forward frame 33/100...\n",
      "Generating forward frame 34/100...\n",
      "Generating forward frame 35/100...\n",
      "Generating forward frame 36/100...\n",
      "Generating forward frame 37/100...\n",
      "Generating forward frame 38/100...\n",
      "Generating forward frame 39/100...\n",
      "Generating forward frame 40/100...\n",
      "Generating forward frame 41/100...\n",
      "Generating forward frame 42/100...\n",
      "Generating forward frame 43/100...\n",
      "Generating forward frame 44/100...\n",
      "Generating forward frame 45/100...\n",
      "Generating forward frame 46/100...\n",
      "Generating forward frame 47/100...\n",
      "Generating forward frame 48/100...\n",
      "Generating forward frame 49/100...\n",
      "Generating forward frame 50/100...\n",
      "Generating forward frame 51/100...\n",
      "Generating forward frame 52/100...\n",
      "Generating forward frame 53/100...\n",
      "Generating forward frame 54/100...\n",
      "Generating forward frame 55/100...\n",
      "Generating forward frame 56/100...\n",
      "Generating forward frame 57/100...\n",
      "Generating forward frame 58/100...\n",
      "Generating forward frame 59/100...\n",
      "Generating forward frame 60/100...\n",
      "Generating forward frame 61/100...\n",
      "Generating forward frame 62/100...\n",
      "Generating forward frame 63/100...\n",
      "Generating forward frame 64/100...\n",
      "Generating forward frame 65/100...\n",
      "Generating forward frame 66/100...\n",
      "Generating forward frame 67/100...\n",
      "Generating forward frame 68/100...\n",
      "Generating forward frame 69/100...\n",
      "Generating forward frame 70/100...\n",
      "Generating forward frame 71/100...\n",
      "Generating forward frame 72/100...\n",
      "Generating forward frame 73/100...\n",
      "Generating forward frame 74/100...\n",
      "Generating forward frame 75/100...\n",
      "Generating forward frame 76/100...\n",
      "Generating forward frame 77/100...\n",
      "Generating forward frame 78/100...\n",
      "Generating forward frame 79/100...\n",
      "Generating forward frame 80/100...\n",
      "Generating forward frame 81/100...\n",
      "Generating forward frame 82/100...\n",
      "Generating forward frame 83/100...\n",
      "Generating forward frame 84/100...\n",
      "Generating forward frame 85/100...\n",
      "Generating forward frame 86/100...\n",
      "Generating forward frame 87/100...\n",
      "Generating forward frame 88/100...\n",
      "Generating forward frame 89/100...\n",
      "Generating forward frame 90/100...\n",
      "Generating forward frame 91/100...\n",
      "Generating forward frame 92/100...\n",
      "Generating forward frame 93/100...\n",
      "Generating forward frame 94/100...\n",
      "Generating forward frame 95/100...\n",
      "Generating forward frame 96/100...\n",
      "Generating forward frame 97/100...\n",
      "Generating forward frame 98/100...\n",
      "Generating forward frame 99/100...\n",
      "Generating forward frame 100/100...\n",
      "video saved as 'morph_loop.mp4'\n"
     ]
    }
   ],
   "source": [
    "# Set up Video Writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_out = cv2.VideoWriter('morph_loop.mp4', fourcc, 15.0, (w, h), isColor=True)  # 15 fps, color video\n",
    "\n",
    "# Create morph frames\n",
    "num_frames = 100  # Forward frames\n",
    "frames = []\n",
    "\n",
    "# Generate forward morph\n",
    "for i, alpha in enumerate(np.linspace(0, 1, num_frames)):\n",
    "    print(f\"Generating forward frame {i+1}/{num_frames}...\")\n",
    "    frame = morph_images(img1, img2, points1, points2, tri, alpha)\n",
    "    frames.append(frame)\n",
    "\n",
    "# Now frames[] contains Woman → Lion morph\n",
    "\n",
    "# Write forward frames\n",
    "for frame in frames:\n",
    "    video_out.write(frame)\n",
    "\n",
    "# Write backward frames (skip last frame to avoid repeated frame)\n",
    "for frame in frames[-2::-1]:  # Start second to last frame, reverse\n",
    "    video_out.write(frame)\n",
    "\n",
    "video_out.release()\n",
    "print(\"video saved as 'morph_loop.mp4'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92c809b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing video... Press Enter in the terminal to exit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('morph_loop.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "print(\"Playing video... Press Enter in the terminal to exit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        # If video ended, restart from beginning\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    cv2.imshow('Morph Video Preview', frame)\n",
    "\n",
    "    # Check for keypress every 30ms\n",
    "    if cv2.waitKey(70) == 13:  # 13 is Enter key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60247dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-venv)",
   "language": "python",
   "name": "ml-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
